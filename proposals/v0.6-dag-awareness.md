# Simplex v0.6 Proposal: DAG Awareness

## Background

Simplex was created to address a fundamental problem with natural language prompting: ambiguity and inconsistency. When autonomous agents receive instructions as prose, the same prompt can produce wildly different results across runs. Intent gets lost, edge cases go unspecified, and there is no reliable way to verify that the agent understood what was asked. Simplex introduced structure — landmarks, required examples, completion criteria, error handling — to eliminate that ambiguity without resorting to the opposite extreme of formal workflow composition. Traditional workflow systems require authors to declare execution graphs, step orderings, and explicit handoffs between stages. Simplex occupies the space between these poles: structured enough to be unambiguous, flexible enough to preserve agent autonomy. This produced surprisingly good results. Autonomous agents given nothing more than a Simplex spec — sometimes with no additional context at all — generate workable codebases, apply correct fixes, and coordinate multi-step operations.

Five iterations of the spec refined this approach. Pillars were consolidated, landmarks were added for evolution tracking (BASELINE, EVAL) and variance control (DETERMINISM), and tooling matured around a Go linter that enforces structural and semantic validity. Through all of this, composition remained explicitly absent. The spec's Composition section states the position directly: "This is intentional and represents a research hypothesis."

That hypothesis has held. But a related observation emerged from practical use.

## The Observation

Simplex already describes graphs. It just does so in a way that only humans can read.

When a function declares `WRITES: SharedMemory.artifacts["compiled_output"]` and another declares `READS: SharedMemory.artifacts["compiled_output"]`, there is an edge between them. When a function declares `TRIGGERS: SharedMemory.status["compilation"] != success`, there is a conditional activation relationship. These edges exist whether or not tooling can see them.

The question that emerged was not whether to add composition to Simplex. The answer to that remains no. The question was whether the data flow relationships that authors already express in prose should be parseable enough for tooling to verify.

Consider the failure modes. An author renames a key in WRITES but forgets to update the corresponding READS in another function. A TRIGGERS block watches a status value that no function ever produces. A function declares outputs that nothing consumes, suggesting either a missing consumer or dead code. These are precisely the kinds of errors that the enforced simplicity pillar exists to catch — yet the current linter cannot detect them because READS, WRITES, and TRIGGERS carry no structure that tooling can match.

## Motivation

The idea that led to this proposal is straightforward: Simplex should not prescribe a DAG, but it should be DAG-aware. The graph that already exists implicitly in every multi-function specification should be observable and verifiable without changing Simplex's fundamental position on composition.

This is a fitting next step for several reasons. It does not expand the spec's surface area. No new landmarks are introduced. The three data flow landmarks (READS, WRITES, TRIGGERS) gain a recommended structured format, but their purpose and optionality are unchanged. It strengthens the enforced simplicity pillar by extending linter coverage to inter-function consistency. And it preserves the research hypothesis about emergent sequencing — the graph is a diagnostic tool, not an orchestration mechanism.

It is worth being precise about what this change does and does not improve. Every prior Simplex version bump expanded the spec's expressive power — gave authors new ways to communicate intent to agents. BASELINE and EVAL in v0.4 let authors describe evolution. DETERMINISM in v0.5 let authors constrain variance. DAG awareness does neither. An LLM reading a v0.6 spec understands no more about a single function than it would reading the same function in v0.5. The prose in READS and WRITES is already perfectly legible to a model. Structured keys do not make the spec more interpretable.

What they make it is more verifiable. The value is in catching human errors — a renamed key, a missing producer, an orphaned output — before those errors reach the agent at all. This is engineering infrastructure: it improves the reliability of multi-function specifications by letting tooling validate data contracts that were previously invisible to it. The benefit scales with the complexity of the system being specified, and is negligible for single-function specs.

This also means the change is motivated by where autonomous agent systems are heading. Multi-agent architectures increasingly involve many specialized agents reading and writing shared state. As the number of agents and the complexity of their data contracts grow, the gap between what the spec says and what tooling can verify becomes a source of real failures. Making data flow edges parseable closes that gap without compromising agent autonomy.

## Design Principles

Three principles guide this change.

First, the DAG is emergent. Specification authors do not declare a graph. They declare what each function reads and writes. The graph follows from those declarations. This preserves implementation autonomy. An agent that discovers a more efficient execution order than the implied DAG is free to use it.

Second, each specification remains independently valid. A function with no READS, WRITES, or TRIGGERS is a standalone unit. Adding data flow landmarks makes relationships visible to tooling but does not change the function's validity. A minimal spec (FUNCTION, RULES, DONE_WHEN, EXAMPLES, ERRORS) is still a minimal spec.

Third, the change is backward compatible. Existing v0.5 specifications that use free-form READS/WRITES/TRIGGERS remain valid. The linter treats unparseable entries as warnings rather than errors. Authors can migrate at their own pace.

## Changes

### Parseable Data Flow Declarations

READS and WRITES entries gain a structured format. Each entry names a key and optionally specifies a type or shape. The format is `key: description` where `key` is a dotted path that tooling can match across landmarks.

Current v0.5 style (still accepted):

```
READS:
  - SharedMemory.artifacts["registry_path"]
```

Proposed v0.6 style:

```
READS:
  - artifacts.registry_path: path to the policy registry file
```

The dotted-path format (`artifacts.registry_path`) gives tooling a stable identifier to match against WRITES entries in other functions. The description after the colon remains free-form prose for human and agent consumption.

WRITES follows the same convention:

```
WRITES:
  - artifacts.compiled_output: compiled agent artifacts ready for deployment
  - status.compilation: success | failure
```

TRIGGERS entries reference keys from WRITES with a condition:

```
TRIGGERS:
  - artifacts.registry_path exists
  - status.compilation != success
```

The key before the condition operator must match a key declared in some function's WRITES block. The condition operators are `exists`, `==`, and `!=`. These are deliberately minimal. Complex activation logic belongs in the agent, not the spec.

### Graph Consistency Checks

The linter gains three new checks.

**Dangling reads (E070).** A READS entry references a key that no function in the specification declares in WRITES. This suggests a missing producer or a typo in the key name.

**Dangling triggers (E071).** A TRIGGERS entry references a key that no function declares in WRITES. The trigger can never fire because nothing produces the value it watches.

**Unreachable writes (W060).** A WRITES entry declares a key that no function references in READS or TRIGGERS. This is a warning, not an error. The output may be consumed by systems outside the specification.

These checks run only when the specification contains multiple functions with data flow landmarks. A single-function spec or a spec without READS/WRITES is unaffected.

### Multi-Spec Analysis

When the linter receives multiple specification files, it performs cross-spec graph analysis. The same consistency checks apply, but across file boundaries. A function in `auth.simplex` that WRITES `session.token` satisfies a READS reference to `session.token` in `api.simplex`.

Cross-spec analysis is optional. The linter defaults to single-file mode. A `--multi` flag or equivalent configuration enables cross-file checking.

### Self-Containment Preserved

The completeness pillar still holds. A function that READS `artifacts.registry_path` must still be understandable and testable on its own. The READS landmark tells tooling about a dependency, but the function's RULES, EXAMPLES, and DONE_WHEN must make sense without resolving that dependency. In practice, this means examples provide concrete values for read keys rather than deferring to the graph.

## Linter Specification Additions

The following functions extend the existing linter specification.

```
FUNCTION: parse_data_flow_key(entry) -> key, description

  RULES:
    - split entry on first colon
    - left side is the key, trimmed of whitespace
    - right side is the description, trimmed of whitespace
    - key must be a dotted path (one or more segments separated by dots)
    - segments contain alphanumeric characters and underscores
    - if entry does not contain a colon, the entire entry is the key with empty description
    - if key is not a valid dotted path, return the raw entry as an unparseable key

  DONE_WHEN:
    - key extracted from entry
    - description extracted or empty

  EXAMPLES:
    ("artifacts.registry_path: path to registry") -> ("artifacts.registry_path", "path to registry")
    ("status.compilation: success | failure") -> ("status.compilation", "success | failure")
    ("artifacts.compiled_output") -> ("artifacts.compiled_output", "")
    ("SharedMemory.artifacts[\"registry\"]") -> unparseable, raw entry returned

  ERRORS:
    - any unhandled condition -> fail with descriptive message

FUNCTION: check_graph_consistency(functions) -> list of LintError

  RULES:
    - collect all parseable WRITES keys across all functions
    - collect all parseable READS keys across all functions
    - collect all parseable TRIGGERS keys across all functions
    - for each READS key, check that at least one function declares it in WRITES
    - missing WRITES for a READS key -> error E070 "dangling read: '{key}' not produced by any function"
    - for each TRIGGERS key, check that at least one function declares it in WRITES
    - missing WRITES for a TRIGGERS key -> error E071 "dangling trigger: '{key}' not produced by any function"
    - for each WRITES key, check if any function references it in READS or TRIGGERS
    - unreferenced WRITES key -> warning W060 "unreachable write: '{key}' not consumed by any function"
    - skip unparseable entries (they cannot participate in graph checks)
    - if all entries are unparseable, return empty list (no graph to check)

  DONE_WHEN:
    - all READS keys checked against WRITES
    - all TRIGGERS keys checked against WRITES
    - all WRITES keys checked for consumers
    - errors and warnings collected

  EXAMPLES:
    (fn1 WRITES artifacts.output, fn2 READS artifacts.output) -> []
    (fn1 READS artifacts.input, no WRITES for artifacts.input) -> [E070]
    (fn1 TRIGGERS status.done, no WRITES for status.done) -> [E071]
    (fn1 WRITES artifacts.unused, no READS or TRIGGERS) -> [W060]
    (all entries unparseable) -> []

  ERRORS:
    - any unhandled condition -> fail with descriptive message
```

## Impact on Existing Landmarks

No existing landmarks change meaning. The five required landmarks (FUNCTION, RULES, DONE_WHEN, EXAMPLES, ERRORS) are unchanged. BASELINE and EVAL are unchanged. DETERMINISM, UNCERTAIN, NOT_ALLOWED, HANDOFF, CONSTRAINT, and DATA are unchanged.

READS, WRITES, and TRIGGERS remain optional. Their content format gains a recommended structured form, but the old free-form style is accepted with a linter warning suggesting migration.

## Impact on the Meta-Specification

The meta-specification's `parse_spec` function gains awareness of data flow keys. Its RULES add one entry: "READS, WRITES, and TRIGGERS entries are parsed for dotted-path keys when present." The `validate_spec` function adds graph consistency checking to its rules when multiple functions with data flow landmarks exist.

The self-description constraint still holds. The updated specification passes its own linter.

## Version History Entry

**v0.6** — Tightened READS, WRITES, and TRIGGERS into parseable data flow declarations using dotted-path keys. Added linter checks for graph consistency: dangling reads (E070), dangling triggers (E071), and unreachable writes (W060). Added optional multi-spec analysis for cross-file graph verification. The dependency graph emerges from declarations rather than being explicitly composed. Each specification remains independently valid and self-contained.

*v0.6 data flow changes address the gap between implicit coordination (prose-based READS/WRITES) and verifiable coordination (structured keys that tooling can match). The DAG is an observation tool, not an orchestration mechanism. Agents retain full autonomy over execution order.*

## Open Questions

**Key namespace conventions.** Should Simplex recommend a namespace hierarchy (e.g., `artifacts.*`, `status.*`, `config.*`), or leave key naming entirely to authors? A recommended convention would improve consistency across projects but risks overspecification.

**Typed values.** The current proposal keeps WRITES descriptions as free-form prose. A future revision could allow optional type annotations (`status.compilation: enum(success, failure)`) that enable deeper validation. This is deliberately deferred to avoid scope creep.

**Cycle detection.** The graph consistency checks verify that edges connect. They do not check for cycles. A cycle (function A reads what B writes, B reads what A writes) may indicate a design error or a legitimate feedback loop. Whether the linter should flag cycles is an open question.
